{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d1edec5",
   "metadata": {},
   "source": [
    "# Required Imports & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bbb139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\berna\\anaconda3\\envs\\CSC9010\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import ast\n",
    "import pandas as pd\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import json\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from evaluate import load as load_metric\n",
    "from transformers import TrainerCallback\n",
    "\n",
    "\n",
    "class PrintStepCallback(TrainerCallback):\n",
    "    def on_step_end(self, args, state, control, **kwargs):\n",
    "        if state.global_step % 10 == 0:\n",
    "            loss = state.log_history[-1].get('loss', 'N/A') if state.log_history else 'N/A'\n",
    "            print(f\"Step {state.global_step}, Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4018c531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DEVICE: cuda\n"
     ]
    }
   ],
   "source": [
    "target_device = ''\n",
    "if torch.backends.mps.is_available():\n",
    "    target_device = 'mps'\n",
    "elif torch .cuda.is_available():\n",
    "    target_device = 'cuda'\n",
    "else:\n",
    "    target_device = 'cpu'\n",
    "\n",
    "DEVICE = torch.device(target_device)\n",
    "print(\"Using DEVICE:\", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c746cba",
   "metadata": {},
   "source": [
    "# Constants/Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c470c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the incoming .json dataset\n",
    "TITLE = 'title'\n",
    "DESCRIPTION = 'description'\n",
    "SUMMARY = 'summary'\n",
    "DATA_SLICE = None\n",
    "\n",
    "# Model hyperparameters\n",
    "MAX_LENGTH = 512        # len\n",
    "MAX_TEXT_TOKENS = 350   # tt\n",
    "\n",
    "MAX_NEW_TOKENS = 1000   # nt\n",
    "EPOCHS = 30             # ep\n",
    "\n",
    "OUTPUT_DIR = f'./qwen_len{MAX_LENGTH}_tt{MAX_TEXT_TOKENS}_nt{MAX_NEW_TOKENS}_ep{EPOCHS}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4d0f3f",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13d705db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_row_text(s):\n",
    "    lst = ast.literal_eval(s)\n",
    "    json_str = json.dumps(lst)\n",
    "    obj = json.loads(json_str)\n",
    "    return obj[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34e4f3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_text(text, tokenizer, max_tokens):\n",
    "    tokens = tokenizer.encode(text, add_special_tokens=False)\n",
    "    if len(tokens) > max_tokens:\n",
    "        tokens = tokens[:max_tokens]\n",
    "        text = tokenizer.decode(tokens, skip_special_tokens=True)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "052b786d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(batch, tokenizer):\n",
    "    input_ids_list = []\n",
    "    attention_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    for summary, description in zip(batch[SUMMARY], batch[DESCRIPTION]):\n",
    "        summary = truncate_text(summary, tokenizer, MAX_TEXT_TOKENS)\n",
    "        \n",
    "        # prompt = f\"Summarize this patent:\\n\\n{text}\\n\\nSummary: \"\n",
    "        prompt = f\"Generate a full detailed patent document based on this summary: \\n\\n{summary}\\n\\n Patent Document:\"\n",
    "        target = description + tokenizer.eos_token\n",
    "        full_text = prompt + target\n",
    "\n",
    "        target_ids = tokenizer.encode(target, add_special_tokens=False)\n",
    "        target_len = len(target_ids)\n",
    "\n",
    "        tokenized = tokenizer(\n",
    "            full_text,\n",
    "            truncation=True,\n",
    "            max_length=MAX_LENGTH,\n",
    "            padding=\"max_length\",\n",
    "            add_special_tokens=True,\n",
    "        )\n",
    "\n",
    "        input_ids = tokenized[\"input_ids\"]\n",
    "        attention_mask = tokenized[\"attention_mask\"]\n",
    "        seq_len = sum(attention_mask)\n",
    "\n",
    "        labels = [-100] * MAX_LENGTH\n",
    "        target_start = seq_len - target_len\n",
    "        \n",
    "        for i in range(target_len):\n",
    "            pos = target_start + i\n",
    "            if 0 <= pos < MAX_LENGTH:\n",
    "                labels[pos] = input_ids[pos]\n",
    "\n",
    "        input_ids_list.append(input_ids)\n",
    "        attention_list.append(attention_mask)\n",
    "        labels_list.append(labels)\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids_list,\n",
    "        \"attention_mask\": attention_list,\n",
    "        \"labels\": labels_list\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0f96e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(mdl, text, tokenizer):\n",
    "    text = truncate_text(text, tokenizer, MAX_TEXT_TOKENS)\n",
    "    # prompt = f\"Summarize this patent:\\n\\n{text}\\n\\nSummary:\"\n",
    "    prompt = f\"Generate a full patent document based on this summary: \\n\\n{text}\\n\\n Patent Document:\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")#.to(\"cuda\")\n",
    "    inputs = {k: v.to(DEVICE) for k, v in inputs.items()}  # move to DEVICE (CPU or GPU)\n",
    "\n",
    "    mdl.eval()\n",
    "    with torch.no_grad():\n",
    "        output = mdl.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=MAX_NEW_TOKENS,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    \n",
    "    full_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    if \"Patent Document:\" in full_output:\n",
    "        return full_output.split(\"Patent Document:\")[-1].strip()\n",
    "    return full_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59e48abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return {\n",
    "        \"input_ids\": torch.tensor([x[\"input_ids\"] for x in batch], dtype=torch.long),\n",
    "        \"attention_mask\": torch.tensor([x[\"attention_mask\"] for x in batch], dtype=torch.long),\n",
    "        \"labels\": torch.tensor([x[\"labels\"] for x in batch], dtype=torch.long),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef703b5",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fde2ddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 0. Prepare Data\n",
    "# ================================================================\n",
    "FILE_NAME = 'us_smallest_claims_1985_1990_top500'\n",
    "CSV_PATH = './' + FILE_NAME + '.csv'\n",
    "JSON_PATH = './' + FILE_NAME + '.json'\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df.drop(columns=['n_claims', 'publication_number', 'publication_date', 'claims_localized_html'], inplace=True)\n",
    "df = df.map(clean_row_text)\n",
    "df.to_json(JSON_PATH, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2eeafab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 500 patents with real summaries\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 1. Load Data\n",
    "# ================================================================\n",
    "# DATA_PATH = \"./us_smallest_claims_1985_1990_top500.json\"\n",
    "DATA_PATH = \"./batch_summarized.json\"\n",
    "\n",
    "with open(DATA_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "if DATA_SLICE:\n",
    "    data = data[:DATA_SLICE]\n",
    "\n",
    "print(f\"Loaded {len(data)} patents with real summaries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a845336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example 1: Vehicular turn signal apparatus\n",
      "  Summary: Vehicular turn signal apparatus is provided for securement to a rear shelf surface proximate a rear window of a vehicular interior. The apparatus incl...\n",
      "\n",
      "Example 2: Apparatus for facilitating the machining of workpieces\n",
      "  Summary: Apparatus for facilitating the machining of workpieces. Means to gain access to the cutting edge of a saw tooth in the direction of both the back and ...\n",
      "\n",
      "Example 3: Control valve\n",
      "  Summary: A 3/2 proportional control valve is provided with an actuating piston which is subjected to the control pressure set in a pilot valve. The area relati...\n",
      "\n",
      "Total records: 500\n"
     ]
    }
   ],
   "source": [
    "records = []\n",
    "for i, item in enumerate(data):\n",
    "    if SUMMARY in item and DESCRIPTION in item:\n",
    "        records.append({\n",
    "            DESCRIPTION: item[DESCRIPTION],\n",
    "            TITLE: item[TITLE],\n",
    "            SUMMARY: item[SUMMARY]\n",
    "        })\n",
    "        if i < 3:\n",
    "            print(f\"\\nExample {i+1}: {item[TITLE]}\")\n",
    "            print(f\"  Summary: {item[SUMMARY][:150]}...\")\n",
    "\n",
    "print(f\"\\nTotal records: {len(records)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955e5cc1",
   "metadata": {},
   "source": [
    "# Model Loading, Fine-Tuning, and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e23c1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 2. Load Model/Tokenizer\n",
    "# ================================================================\n",
    "model_name = \"Qwen/Qwen3-0.6B-Base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True,\n",
    "    # use bfloat16 only if CUDA is available; otherwise use float32\n",
    "    torch_dtype=(torch.bfloat16 if torch.cuda.is_available() else torch.float32),\n",
    ")\n",
    "model.to(DEVICE)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3878e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train: 400, Test: 100\n",
      "{'description': 'A protective trim system is provided which protects the surface of an underlying solid body. The system includes an elongated trim member which is attached to a surface and is movable away from the surface to protect the underlying body.', 'title': 'Extendable protective trim', 'summary': 'A protective trim system is provided which protects the surface of an underlying solid body. System includes an elongated trim member which is attached to a surface and is movable away from the surface to protect the underlying body. The system also comprises a deflatable bladder disposed between said mountingflange and said trim member.'}\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 3. Create Dataset\n",
    "# ================================================================\n",
    "\n",
    "dataset = Dataset.from_list(records)\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "print(f\"\\nTrain: {len(dataset['train'])}, Test: {len(dataset['test'])}\")\n",
    "print(dataset['test'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "361d4efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 400/400 [00:00<00:00, 946.44 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid label tokens: 105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 4. Preprocessing\n",
    "# ================================================================\n",
    "tokenized_train = dataset[\"train\"].map(\n",
    "    lambda batch: preprocess(batch, tokenizer),\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names\n",
    ")\n",
    "\n",
    "example = tokenized_train[0]\n",
    "valid_count = sum(1 for l in example[\"labels\"] if l != -100)\n",
    "print(f\"Valid label tokens: {valid_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2856dbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline evaluation...\n",
      "Baseline ROUGE-L: 0.3224\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 5. Baseline Evaluation\n",
    "# ================================================================\n",
    "rouge = load_metric(\"rouge\")\n",
    "\n",
    "# test_refs = [item[SUMMARY] for item in dataset[\"test\"]]\n",
    "test_refs = [item[DESCRIPTION] for item in dataset[\"test\"]]\n",
    "\n",
    "print(\"\\nBaseline evaluation...\")\n",
    "baseline_preds = []\n",
    "for item in dataset[\"test\"]:\n",
    "    pred = generate_summary(model, item[DESCRIPTION], tokenizer)\n",
    "    baseline_preds.append(pred)\n",
    "\n",
    "baseline_rouge = rouge.compute(predictions=baseline_preds, references=test_refs)\n",
    "print(f\"Baseline ROUGE-L: {baseline_rouge['rougeL']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e330dbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 40,370,176 || all params: 636,420,096 || trainable%: 6.3433\n",
      "\n",
      "=== Training ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 33:41, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.694400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.653000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.566400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.518700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.396000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.595000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.572600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.565600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.506900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.495500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.384800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.377100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.342300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.441300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.155800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.240900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.157500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.195400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.254100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.918100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.955200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.002800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.974500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.969100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.735900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.760600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.672300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.765100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.713600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.536400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.505400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.492600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.519700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.528800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.340400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.358400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.320700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.329100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.382400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.236500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.186200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.213400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.240700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.232200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.146700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.138300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.114300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.161200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.127600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.082100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.088500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.092400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.081700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.102300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.054600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.069500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.051400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.066800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.069600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.034100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.047400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.046200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.042400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.046100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.035800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.029200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.040700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.029900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.032500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.018000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.028000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.028300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.028000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.026300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.018500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.018100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.015200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>0.014700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.018000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>0.010700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.010600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>0.014100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.012100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.009500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>0.006900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.007100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>0.007900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.010900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>0.008800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.005700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>0.005500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.005400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.004800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.004400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>0.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>0.002600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.004200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>0.002500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.004300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>0.002700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>0.002500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>0.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>0.002100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.002300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>0.001800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>0.001800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130</td>\n",
       "      <td>0.002100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.001800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>0.001600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>0.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>0.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1190</td>\n",
       "      <td>0.001800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1210</td>\n",
       "      <td>0.001800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>0.001600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230</td>\n",
       "      <td>0.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>0.001600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.001600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1270</td>\n",
       "      <td>0.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>0.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290</td>\n",
       "      <td>0.001600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.001600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1310</td>\n",
       "      <td>0.001600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.001600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1330</td>\n",
       "      <td>0.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1340</td>\n",
       "      <td>0.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.001600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1360</td>\n",
       "      <td>0.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1370</td>\n",
       "      <td>0.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1390</td>\n",
       "      <td>0.001600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.001600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1410</td>\n",
       "      <td>0.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1420</td>\n",
       "      <td>0.001600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1430</td>\n",
       "      <td>0.001400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.001600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1460</td>\n",
       "      <td>0.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1470</td>\n",
       "      <td>0.001600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1480</td>\n",
       "      <td>0.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1490</td>\n",
       "      <td>0.001600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.001400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10, Loss: N/A\n",
      "Step 20, Loss: 1.77\n",
      "Step 30, Loss: 1.6944\n",
      "Step 40, Loss: 1.653\n",
      "Step 50, Loss: 1.5664\n",
      "Step 60, Loss: 1.5187\n",
      "Step 70, Loss: 1.396\n",
      "Step 80, Loss: 1.595\n",
      "Step 90, Loss: 1.5726\n",
      "Step 100, Loss: 1.5656\n",
      "Step 110, Loss: 1.5069\n",
      "Step 120, Loss: 1.4955\n",
      "Step 130, Loss: 1.3848\n",
      "Step 140, Loss: 1.3771\n",
      "Step 150, Loss: 1.3423\n",
      "Step 160, Loss: 1.4413\n",
      "Step 170, Loss: 1.1558\n",
      "Step 180, Loss: 1.2409\n",
      "Step 190, Loss: 1.1575\n",
      "Step 200, Loss: 1.1954\n",
      "Step 210, Loss: 1.2541\n",
      "Step 220, Loss: 0.9181\n",
      "Step 230, Loss: 0.9552\n",
      "Step 240, Loss: 1.0028\n",
      "Step 250, Loss: 0.9745\n",
      "Step 260, Loss: 0.9691\n",
      "Step 270, Loss: 0.7359\n",
      "Step 280, Loss: 0.7606\n",
      "Step 290, Loss: 0.6723\n",
      "Step 300, Loss: 0.7651\n",
      "Step 310, Loss: 0.7136\n",
      "Step 320, Loss: 0.5364\n",
      "Step 330, Loss: 0.5054\n",
      "Step 340, Loss: 0.4926\n",
      "Step 350, Loss: 0.5197\n",
      "Step 360, Loss: 0.5288\n",
      "Step 370, Loss: 0.3404\n",
      "Step 380, Loss: 0.3584\n",
      "Step 390, Loss: 0.3207\n",
      "Step 400, Loss: 0.3291\n",
      "Step 410, Loss: 0.3824\n",
      "Step 420, Loss: 0.2365\n",
      "Step 430, Loss: 0.1862\n",
      "Step 440, Loss: 0.2134\n",
      "Step 450, Loss: 0.2407\n",
      "Step 460, Loss: 0.2322\n",
      "Step 470, Loss: 0.1467\n",
      "Step 480, Loss: 0.1383\n",
      "Step 490, Loss: 0.1143\n",
      "Step 500, Loss: 0.1612\n",
      "Step 510, Loss: 0.1276\n",
      "Step 520, Loss: 0.0821\n",
      "Step 530, Loss: 0.0885\n",
      "Step 540, Loss: 0.0924\n",
      "Step 550, Loss: 0.0817\n",
      "Step 560, Loss: 0.1023\n",
      "Step 570, Loss: 0.0546\n",
      "Step 580, Loss: 0.0695\n",
      "Step 590, Loss: 0.0514\n",
      "Step 600, Loss: 0.0668\n",
      "Step 610, Loss: 0.0696\n",
      "Step 620, Loss: 0.0341\n",
      "Step 630, Loss: 0.0474\n",
      "Step 640, Loss: 0.0462\n",
      "Step 650, Loss: 0.0424\n",
      "Step 660, Loss: 0.0461\n",
      "Step 670, Loss: 0.0358\n",
      "Step 680, Loss: 0.0292\n",
      "Step 690, Loss: 0.0407\n",
      "Step 700, Loss: 0.0299\n",
      "Step 710, Loss: 0.0325\n",
      "Step 720, Loss: 0.018\n",
      "Step 730, Loss: 0.028\n",
      "Step 740, Loss: 0.0283\n",
      "Step 750, Loss: 0.028\n",
      "Step 760, Loss: 0.0263\n",
      "Step 770, Loss: 0.0185\n",
      "Step 780, Loss: 0.0181\n",
      "Step 790, Loss: 0.0152\n",
      "Step 800, Loss: 0.0147\n",
      "Step 810, Loss: 0.018\n",
      "Step 820, Loss: 0.0107\n",
      "Step 830, Loss: 0.0106\n",
      "Step 840, Loss: 0.0141\n",
      "Step 850, Loss: 0.01\n",
      "Step 860, Loss: 0.0121\n",
      "Step 870, Loss: 0.0095\n",
      "Step 880, Loss: 0.0069\n",
      "Step 890, Loss: 0.0071\n",
      "Step 900, Loss: 0.0079\n",
      "Step 910, Loss: 0.0109\n",
      "Step 920, Loss: 0.0088\n",
      "Step 930, Loss: 0.0057\n",
      "Step 940, Loss: 0.0055\n",
      "Step 950, Loss: 0.0054\n",
      "Step 960, Loss: 0.0048\n",
      "Step 970, Loss: 0.0044\n",
      "Step 980, Loss: 0.004\n",
      "Step 990, Loss: 0.0031\n",
      "Step 1000, Loss: 0.0026\n",
      "Step 1010, Loss: 0.0042\n",
      "Step 1020, Loss: 0.0025\n",
      "Step 1030, Loss: 0.0043\n",
      "Step 1040, Loss: 0.0027\n",
      "Step 1050, Loss: 0.0025\n",
      "Step 1060, Loss: 0.0031\n",
      "Step 1070, Loss: 0.0031\n",
      "Step 1080, Loss: 0.002\n",
      "Step 1090, Loss: 0.0019\n",
      "Step 1100, Loss: 0.0021\n",
      "Step 1110, Loss: 0.0023\n",
      "Step 1120, Loss: 0.0018\n",
      "Step 1130, Loss: 0.0018\n",
      "Step 1140, Loss: 0.0021\n",
      "Step 1150, Loss: 0.0018\n",
      "Step 1160, Loss: 0.0019\n",
      "Step 1170, Loss: 0.0016\n",
      "Step 1180, Loss: 0.0017\n",
      "Step 1190, Loss: 0.0017\n",
      "Step 1200, Loss: 0.0018\n",
      "Step 1210, Loss: 0.0017\n",
      "Step 1220, Loss: 0.0018\n",
      "Step 1230, Loss: 0.0016\n",
      "Step 1240, Loss: 0.0017\n",
      "Step 1250, Loss: 0.0016\n",
      "Step 1260, Loss: 0.0016\n",
      "Step 1270, Loss: 0.0015\n",
      "Step 1280, Loss: 0.0017\n",
      "Step 1290, Loss: 0.0017\n",
      "Step 1300, Loss: 0.0016\n",
      "Step 1310, Loss: 0.0016\n",
      "Step 1320, Loss: 0.0016\n",
      "Step 1330, Loss: 0.0016\n",
      "Step 1340, Loss: 0.0015\n",
      "Step 1350, Loss: 0.0015\n",
      "Step 1360, Loss: 0.0016\n",
      "Step 1370, Loss: 0.0017\n",
      "Step 1380, Loss: 0.0015\n",
      "Step 1390, Loss: 0.0015\n",
      "Step 1400, Loss: 0.0016\n",
      "Step 1410, Loss: 0.0016\n",
      "Step 1420, Loss: 0.0015\n",
      "Step 1430, Loss: 0.0016\n",
      "Step 1440, Loss: 0.0014\n",
      "Step 1450, Loss: 0.0015\n",
      "Step 1460, Loss: 0.0016\n",
      "Step 1470, Loss: 0.0015\n",
      "Step 1480, Loss: 0.0016\n",
      "Step 1490, Loss: 0.0015\n",
      "Step 1500, Loss: 0.0016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1500, training_loss=0.30038514609324435, metrics={'train_runtime': 2023.0427, 'train_samples_per_second': 5.932, 'train_steps_per_second': 0.741, 'total_flos': 1.7725598466048e+16, 'train_loss': 0.30038514609324435, 'epoch': 30.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 6. LoRA Fine-tuning\n",
    "# ================================================================\n",
    "config = LoraConfig(\n",
    "    r=64,\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "model = get_peft_model(model, config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=1e-4,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01,\n",
    "    bf16=torch.cuda.is_available(),               # enable bf16 only on CUDA\n",
    "    dataloader_pin_memory=torch.cuda.is_available(),  # only pin when CUDA available\n",
    "    logging_steps=10,\n",
    "    save_steps=999999, # keep this high\n",
    "    report_to=\"none\",\n",
    "    disable_tqdm=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    data_collator=collate_fn,\n",
    "    callbacks=[PrintStepCallback()]\n",
    ")\n",
    "\n",
    "print(\"\\n=== Training ===\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7508fbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final evaluation...\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 7. Final Evaluation\n",
    "# ================================================================\n",
    "print(\"\\nFinal evaluation...\")\n",
    "finetuned_preds = []\n",
    "\n",
    "model.eval()\n",
    "for item in dataset[\"test\"]:\n",
    "    pred = generate_summary(model, item[DESCRIPTION], tokenizer)\n",
    "    finetuned_preds.append(pred)\n",
    "\n",
    "finetuned_rouge = rouge.compute(predictions=finetuned_preds, references=test_refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64758677-d4ae-48b3-8f6c-28290e11977d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SAVING MODEL\n",
      "======================================================================\n",
      "✓ LoRA adapters saved\n",
      "✓ Tokenizer saved\n",
      "✓ Metadata saved\n",
      "✓ Sample predictions saved\n",
      "\n",
      "✓ Complete model package saved to: ./qwen_lora_patent_real/\n",
      "\n",
      "Saved files:\n",
      "  - adapter_model.bin (~13MB)\n",
      "  - adapter_config.json\n",
      "  - tokenizer files\n",
      "  - metadata.json\n",
      "  - sample_predictions.json\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 8. SAVE MODEL PROPERLY\n",
    "# ================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAVING MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Save LoRA adapters\n",
    "model.save_pretrained(\"./qwen_lora_patent_real\")\n",
    "print(\"✓ LoRA adapters saved\")\n",
    "\n",
    "# Save tokenizer\n",
    "tokenizer.save_pretrained(\"./qwen_lora_patent_real\")\n",
    "print(\"✓ Tokenizer saved\")\n",
    "\n",
    "# Save comprehensive metadata\n",
    "metadata = {\n",
    "    \"model_info\": {\n",
    "        \"base_model\": model_name,\n",
    "        \"model_type\": \"LoRA_fine-tuned\",\n",
    "        \"task\": \"patent_summarization\"\n",
    "    },\n",
    "    \"training_info\": {\n",
    "        \"training_date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"dataset\": DATA_PATH,\n",
    "        \"num_train_examples\": len(dataset[\"train\"]),\n",
    "        \"num_test_examples\": len(dataset[\"test\"]),\n",
    "        \"num_epochs\": EPOCHS,\n",
    "        \"batch_size\": 2,\n",
    "        \"gradient_accumulation_steps\": 4,\n",
    "        \"effective_batch_size\": 8,\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"max_length\": MAX_LENGTH,\n",
    "        \"max_text_tokens\": MAX_TEXT_TOKENS\n",
    "    },\n",
    "    \"lora_config\": {\n",
    "        \"r\": 32,\n",
    "        \"lora_alpha\": 64,\n",
    "        \"lora_dropout\": 0.05,\n",
    "        \"target_modules\": [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
    "    },\n",
    "    \"results\": {\n",
    "        \"baseline\": {\n",
    "            \"rouge1\": float(baseline_rouge['rouge1']),\n",
    "            \"rouge2\": float(baseline_rouge['rouge2']),\n",
    "            \"rougeL\": float(baseline_rouge['rougeL'])\n",
    "        },\n",
    "        \"finetuned\": {\n",
    "            \"rouge1\": float(finetuned_rouge['rouge1']),\n",
    "            \"rouge2\": float(finetuned_rouge['rouge2']),\n",
    "            \"rougeL\": float(finetuned_rouge['rougeL'])\n",
    "        },\n",
    "        \"improvement\": {\n",
    "            \"rouge1\": float(finetuned_rouge['rouge1'] - baseline_rouge['rouge1']),\n",
    "            \"rouge2\": float(finetuned_rouge['rouge2'] - baseline_rouge['rouge2']),\n",
    "            \"rougeL\": float(finetuned_rouge['rougeL'] - baseline_rouge['rougeL'])\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(\"./qwen_lora_patent_real/metadata.json\", \"w\") as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(\"✓ Metadata saved\")\n",
    "\n",
    "# Save sample predictions for reference\n",
    "samples = []\n",
    "for i in range(min(5, len(test_refs))):\n",
    "    samples.append({\n",
    "        TITLE: dataset['test'][i][TITLE],\n",
    "        \"reference\": test_refs[i],\n",
    "        \"baseline\": baseline_preds[i],\n",
    "        \"finetuned\": finetuned_preds[i]\n",
    "    })\n",
    "\n",
    "with open(\"./qwen_lora_patent_real/sample_predictions.json\", \"w\") as f:\n",
    "    json.dump(samples, f, indent=2, ensure_ascii=False)\n",
    "print(\"✓ Sample predictions saved\")\n",
    "\n",
    "print(f\"\\n✓ Complete model package saved to: ./qwen_lora_patent_real/\")\n",
    "print(\"\\nSaved files:\")\n",
    "print(\"  - adapter_model.bin (~13MB)\")\n",
    "print(\"  - adapter_config.json\")\n",
    "print(\"  - tokenizer files\")\n",
    "print(\"  - metadata.json\")\n",
    "print(\"  - sample_predictions.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1a9735b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FINAL RESULTS\n",
      "======================================================================\n",
      "Baseline ROUGE-L:   0.3224\n",
      "Fine-tuned ROUGE-L: 0.7598\n",
      "Change: +0.4374 (+43.74%)\n",
      "\n",
      "Detailed scores:\n",
      "  ROUGE-1: 0.3380 -> 0.7890\n",
      "  ROUGE-2: 0.3064 -> 0.7346\n",
      "  ROUGE-L: 0.3224 -> 0.7598\n",
      "\n",
      "=== Sample Comparisons ===\n",
      "\n",
      "--- Extendable protective trim ---\n",
      "Reference:  A protective trim system is provided which protects the surface of an underlying solid body. The system includes an elongated trim member which is attached to a surface and is movable away from the surface to protect the underlying body.\n",
      "Baseline:   [Patent Document]\n",
      "\n",
      "[Abstract] \n",
      "\n",
      "A protective trim system is provided which protects the surface of an underlying solid body. The system includes an elongated trim member which is attached to a surface and is movable away from the surface to protect the underlying body. The trim member is designed to be easily removable and can be used to cover or protect various surfaces, such as windows, doors, and other exposed areas. The system is easy to install and can be used in a variety of applications, including automotive, industrial, and commercial settings. The trim member is made of durable materials that can withstand harsh weather conditions and can be easily cleaned and maintained. The system is also designed to be compatible with a variety of underlying surfaces, making it a versatile and effective solution for protecting exposed areas.\n",
      "\n",
      "[Claims] \n",
      "\n",
      "1. A protective trim system for protecting a surface of an underlying solid body, comprising: \n",
      "\n",
      "a. an elongated trim member; \n",
      "\n",
      "b. a first attachment means for attaching the trim member to the surface; \n",
      "\n",
      "c. a second attachment means for attaching the trim member to the underlying solid body; \n",
      "\n",
      "d. a movable mechanism for moving the trim member away from the surface; \n",
      "\n",
      "e. a removable mechanism for removing the trim member from the underlying solid body; \n",
      "\n",
      "f. a durable material for the trim member; \n",
      "\n",
      "g. a design for the trim member to be compatible with a variety of underlying surfaces; \n",
      "\n",
      "h. a design for the trim member to be easy to install and maintain; \n",
      "\n",
      "i. a design for the trim member to be compatible with a variety of applications.\n",
      "\n",
      "2. The protective trim system of claim 1, wherein the first attachment means is a screw or bolt.\n",
      "\n",
      "3. The protective trim system of claim 1, wherein the second attachment means is a clip or snap.\n",
      "\n",
      "4. The protective trim system of claim 1, wherein the movable mechanism is a sliding mechanism.\n",
      "\n",
      "5. The protective trim system of claim 1, wherein the removable mechanism is a snap or clip.\n",
      "\n",
      "6. The protective trim system of claim 1, wherein the durable material is made of a durable plastic or metal.\n",
      "\n",
      "7. The protective trim system of claim 1, wherein the design for the trim member to be compatible with a variety of underlying surfaces is a design that allows the trim member to be attached to a variety of surfaces, such as glass, metal, and wood.\n",
      "\n",
      "8. The protective trim system of claim 1, wherein the design for the trim member to be easy to install and maintain is a design that allows the trim member to be easily removed and replaced, and that is easy to clean and maintain.\n",
      "\n",
      "9. The protective trim system of claim 1, wherein the design for the trim member to be compatible with a variety of applications is a design that allows the trim member to be used in a variety of applications, such as automotive, industrial, and commercial settings.\n",
      "\n",
      "10. The protective trim system of claim 1, wherein the durable material is made of a durable plastic or metal, and the design for the trim member to be compatible with a variety of underlying surfaces is a design that allows the trim member to be attached to a variety of surfaces, such as glass, metal, and wood.\n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[Claims] \n",
      "\n",
      "[Claims] \n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[Claims] \n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[Claims] \n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[Claims] \n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[Claims] \n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[Claims] \n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[Claims] \n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[Claims] \n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[Claims] \n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[Claims] \n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[Claims] \n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[Claims] \n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[Claims] \n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[Claims] \n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[Claims] \n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[Claims] \n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[Claims] \n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[Claims] \n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[Claims] \n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[Claims] \n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[Claims] \n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[Claims] \n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[Claims] \n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[Claims] \n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[Claims] \n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[Claims] \n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[Claims] \n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[Claims] \n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[Claims] \n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[Claims] \n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[Claims] \n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[Claims] \n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[Claims] \n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[Claims] \n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[Claims] \n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[Claims] \n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[Claims] \n",
      "\n",
      "[Drawings] \n",
      "\n",
      "[\n",
      "Fine-tuned: A protective trim system is provided which protects the surface of an underlying solid body disposed in a formed engagement with a surrounding surface. The system includes an elongated trim member which is attached to a surface and is movable away from the surface to protect the underlying body. In a preferred embodiment for protecting a tubular member formed in the surrounding surface, the trim member is attachable to a wall portion of the tubular member and is movable substantially parallel to the surface being protected.\n",
      "\n",
      "--- Spiral displacement machine with radially inner seal gap for temperature expansion ---\n",
      "Reference:  A spiral displacement machine for compressible media is described which has at least one displacement chamber in the form of a spiral-shaped groove arranged in a stationary housing and also has a spiral rib-shaped displacement body associated with each displacement chamber. Each displacement body is on the side of a disc-shaped rotor which is driven eccentrically in a translatory movement relative to the housing. During operation, each peripheral point of the displacement body performs a circular movement bounded by the peripheral walls of the associated displacement chamber. At the edges of the displacement bodies and of the housing walls forming the displacement chambers, sealing strips mounted in spiral grooves engage the adjacent surfaces of the other component of the machine. In order to ensure the most uniform possible application of the sealing strips against the adjacent surfaces during hot operating states of the displacement machine, the depth of the spiral-shaped sealing grooves and/or the height of the sealing strips is varied over the length of the spiral so that, at ambient temperature, when the sealing strips engage the bottom of the groove, the sealing gap at the radially inner end of the spiral is larger than at the outer end by an amount equal to the difference in expansion of the components at those ends during operation.\n",
      "Baseline:   [1] Patent Document 1: [2] Patent Document 2: [3] Patent Document 3: [4] Patent Document 4: [5] Patent Document 5: [6] Patent Document 6: [7] Patent Document 7: [8] Patent Document 8: [9] Patent Document 9: [10] Patent Document 10: [11] Patent Document 11: [12] Patent Document 12: [13] Patent Document 13: [14] Patent Document 14: [15] Patent Document 15: [16] Patent Document 16: [17] Patent Document 17: [18] Patent Document 18: [19] Patent Document 19: [20] Patent Document 20: [21] Patent Document 21: [22] Patent Document 22: [23] Patent Document 23: [24] Patent Document 24: [25] Patent Document 25: [26] Patent Document 26: [27] Patent Document 27: [28] Patent Document 28: [29] Patent Document 29: [30] Patent Document 30: [31] Patent Document 31: [32] Patent Document 32: [33] Patent Document 33: [34] Patent Document 34: [35] Patent Document 35: [36] Patent Document 36: [37] Patent Document 37: [38] Patent Document 38: [39] Patent Document 39: [40] Patent Document 40: [41] Patent Document 41: [42] Patent Document 42: [43] Patent Document 43: [44] Patent Document 44: [45] Patent Document 45: [46] Patent Document 46: [47] Patent Document 47: [48] Patent Document 48: [49] Patent Document 49: [50] Patent Document 50: [51] Patent Document 51: [52] Patent Document 52: [53] Patent Document 53: [54] Patent Document 54: [55] Patent Document 55: [56] Patent Document 56: [57] Patent Document 57: [58] Patent Document 58: [59] Patent Document 59: [60] Patent Document 60: [61] Patent Document 61: [62] Patent Document 62: [63] Patent Document 63: [64] Patent Document 64: [65] Patent Document 65: [66] Patent Document 66: [67] Patent Document 67: [68] Patent Document 68: [69] Patent Document 69: [70] Patent Document 70: [71] Patent Document 71: [72] Patent Document 72: [73] Patent Document 73: [74] Patent Document 74: [75] Patent Document 75: [76] Patent Document 76: [77] Patent Document 77: [78] Patent Document 78: [79] Patent Document 79: [80] Patent Document 80: [81] Patent Document 81: [82] Patent Document 82: [83] Patent Document 83: [84] Patent Document 84: [85] Patent Document 85: [86] Patent Document 86: [87] Patent Document 87: [88] Patent Document 88: [89] Patent Document 89: [90] Patent Document 90: [91] Patent Document 91: [92] Patent Document 92: [93] Patent Document 93: [94] Patent Document 94: [95] Patent Document 95: [96] Patent Document 96: [97] Patent Document 97: [98] Patent Document 98: [99] Patent Document 99: [100] Patent Document 100: [101] Patent Document 101: [102\n",
      "Fine-tuned: &#34;Spiral displacement machine for compressible media is described which has at least one displacement chamber in the form of a spiral-shaped groove arranged in a stationary housing and also has a spiral rib-shaped displacement body associated with each displacement chamber. Each displacement body is on the side of a disc-shaped rotor which is driven eccentrically in a translatory movement relative to the housing. During operation, each peripheral point of the displacement body performs a circular movement bounded by the peripheral walls of the associated displacement chamber. At the edges of the displacement bodies and of the housing walls forming the displacement chambers, sealing strips mounted in spiral grooves engage the adjacent surfaces of the other component of the machine, and are adapted to engage the bottom of the groove, rather than the ceiling, when the associated housing and displacement body are assumed to be in hot operating condition. In order to ensure the most uniform possible application of the sealing strips against the adjacent surfaces during hot operating states of the displacement machine, the depth of the spiral-shaped sealing grooves and/or the height of the sealing strips is varied over the length of the spiral so that, at ambient temperature, when the sealing strips engage the bottom of the groove, the sealing gap at the radially inner end of the spiral is larger than at the outer end by an amount equal to the difference in expansion of the component at those ends during operation, and also by the same amount as the difference between the inner and outer diameters of the displacement body at the time of installation of the machine.\n",
      "\n",
      "--- Electronically tuned electro-acoustic power oscillator ---\n",
      "Reference:  The electronically tuned power oscillator (ETPO) of the present invention provides a method and apparatus that drives a narrow-band (high Q) transducer over a relatively broad band of frequencies. A pseudo-random sequence generator dynamically switches a bank of capacitors varying the resonant frequency of the power oscillator. A node on the power oscillator provides the clock for the pseudo-random sequence generator thereby providing a synchronized frequency change on every time varying cycle.\n",
      "Baseline:   Title: Electronic Tuned Power Oscillator (ETPO)\n",
      "Abstract: The present invention provides a method and apparatus for driving a narrow-band (high Q) transducer over a relatively broad band of frequencies. The method involves dynamically switching a bank of capacitors to vary the resonant frequency of the power oscillator. The node on the power oscillator serves as the clock for the pseudo-random sequence generator, ensuring synchronization of the frequency changes on every time-varying cycle.\n",
      "\n",
      "Key Features:\n",
      "1. **Narrow-Band Transducer**: The power oscillator is designed to drive a transducer with a high Q factor, ensuring efficient and precise frequency control.\n",
      "2. **Dynamic Frequency Variation**: The resonant frequency of the power oscillator is varied by dynamically switching a bank of capacitors, allowing for a wide range of frequencies to be controlled.\n",
      "3. **Synchronized Clock**: The node on the power oscillator acts as the clock for the pseudo-random sequence generator, ensuring that the frequency changes are synchronized across the transducer.\n",
      "4. **Pseudo-Random Sequence Generator**: The method includes a pseudo-random sequence generator that operates in sync with the frequency changes, providing a stable and predictable output.\n",
      "\n",
      "Patent Application: \n",
      "Title: Electronic Tuned Power Oscillator (ETPO)\n",
      "Abstract: The present invention provides a method and apparatus for driving a narrow-band (high Q) transducer over a relatively broad band of frequencies. The method involves dynamically switching a bank of capacitors to vary the resonant frequency of the power oscillator. The node on the power oscillator serves as the clock for the pseudo-random sequence generator, ensuring synchronization of the frequency changes on every time-varying cycle.\n",
      "\n",
      "Key Features:\n",
      "1. **Narrow-Band Transducer**: The power oscillator is designed to drive a transducer with a high Q factor, ensuring efficient and precise frequency control.\n",
      "2. **Dynamic Frequency Variation**: The resonant frequency of the power oscillator is varied by dynamically switching a bank of capacitors, allowing for a wide range of frequencies to be controlled.\n",
      "3. **Synchronized Clock**: The node on the power oscillator acts as the clock for the pseudo-random sequence generator, ensuring that the frequency changes are synchronized across the transducer.\n",
      "4. **Pseudo-Random Sequence Generator**: The method includes a pseudo-random sequence generator that operates in sync with the frequency changes, providing a stable and predictable output.\n",
      "\n",
      "Patent Application: \n",
      "Title: Electronic Tuned Power Oscillator (ETPO)\n",
      "Abstract: The present invention provides a method and apparatus for driving a narrow-band (high Q) transducer over a relatively broad band of frequencies. The method involves dynamically switching a bank of capacitors to vary the resonant frequency of the power oscillator. The node on the power oscillator serves as the clock for the pseudo-random sequence generator, ensuring synchronization of the frequency changes on every time-varying cycle.\n",
      "\n",
      "Key Features:\n",
      "1. **Narrow-Band Transducer**: The power oscillator is designed to drive a transducer with a high Q factor, ensuring efficient and precise frequency control.\n",
      "2. **Dynamic Frequency Variation**: The resonant frequency of the power oscillator is varied by dynamically switching a bank of capacitors, allowing for a wide range of frequencies to be controlled.\n",
      "3. **Synchronized Clock**: The node on the power oscillator acts as the clock for the pseudo-random sequence generator, ensuring that the frequency changes are synchronized across the transducer.\n",
      "4. **Pseudo-Random Sequence Generator**: The method includes a pseudo-random sequence generator that operates in sync with the frequency changes, providing a stable and predictable output.\n",
      "\n",
      "Patent Application: \n",
      "Title: Electronic Tuned Power Oscillator (ETPO)\n",
      "Abstract: The present invention provides a method and apparatus for driving a narrow-band (high Q) transducer over a relatively broad band of frequencies. The method involves dynamically switching a bank of capacitors to vary the resonant frequency of the power oscillator. The node on the power oscillator serves as the clock for the pseudo-random sequence generator, ensuring synchronization of the frequency changes on every time-varying cycle.\n",
      "\n",
      "Key Features:\n",
      "1. **Narrow-Band Transducer**: The power oscillator is designed to drive a transducer with a high Q factor, ensuring efficient and precise frequency control.\n",
      "2. **Dynamic Frequency Variation**: The resonant frequency of the power oscillator is varied by dynamically switching a bank of capacitors, allowing for a wide range of frequencies to be controlled.\n",
      "3. **Synchronized Clock**: The node on the power oscillator acts as the clock for the pseudo-random sequence generator, ensuring that the frequency changes are synchronized across the transducer.\n",
      "4. **Pseudo-Random Sequence Generator**: The method includes a pseudo-random sequence generator that operates in sync with the frequency changes, providing a stable and predictable output.\n",
      "\n",
      "Patent Application: \n",
      "Title: Electronic Tuned Power Oscillator (ETPO)\n",
      "Abstract: The present invention provides a method and apparatus for driving a narrow-band (high Q) transducer over a\n",
      "Fine-tuned: The electronically tuned power oscillator (ETPO) of the present invention provides a method and apparatus that drives a narrow-band (high Q) transducer over a relatively broad band of frequencies. A pseudo-random sequence generator dynamically switches a bank of capacitors varying the resonant frequency of the power oscillator in order to vary the load resistance of a filter after which the sequence is repeated. A node on the power oscillator provides the clock for the pseudo-random sequence generator thereby providing a synchronized frequency change on every time varying cycle.\n",
      "\n",
      "======================================================================\n",
      "TRAINING COMPLETE!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 9. Display Results\n",
    "# ================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Baseline ROUGE-L:   {baseline_rouge['rougeL']:.4f}\")\n",
    "print(f\"Fine-tuned ROUGE-L: {finetuned_rouge['rougeL']:.4f}\")\n",
    "delta = finetuned_rouge['rougeL'] - baseline_rouge['rougeL']\n",
    "print(f\"Change: {'+' if delta >= 0 else ''}{delta:.4f} ({delta*100:+.2f}%)\")\n",
    "\n",
    "print(f\"\\nDetailed scores:\")\n",
    "print(f\"  ROUGE-1: {baseline_rouge['rouge1']:.4f} -> {finetuned_rouge['rouge1']:.4f}\")\n",
    "print(f\"  ROUGE-2: {baseline_rouge['rouge2']:.4f} -> {finetuned_rouge['rouge2']:.4f}\")\n",
    "print(f\"  ROUGE-L: {baseline_rouge['rougeL']:.4f} -> {finetuned_rouge['rougeL']:.4f}\")\n",
    "\n",
    "print(\"\\n=== Sample Comparisons ===\")\n",
    "for i in range(min(3, len(test_refs))):\n",
    "    print(f\"\\n--- {dataset['test'][i][TITLE]} ---\")\n",
    "    print(f\"Reference:  {test_refs[i][:]}\")\n",
    "    print(f\"Baseline:   {baseline_preds[i][:]}\")\n",
    "    print(f\"Fine-tuned: {finetuned_preds[i][:]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251205eb",
   "metadata": {},
   "source": [
    "# Load and Prompt Existing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62746b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 prompts for our model!\n"
     ]
    }
   ],
   "source": [
    "PROMPT_PATH = \"./prompt-construction/patent_prompts.json\"\n",
    "\n",
    "with open(PROMPT_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    prompts = json.load(f)\n",
    "\n",
    "prompts = prompts[:10]\n",
    "\n",
    "print(f\"Loaded {len(prompts)} prompts for our model!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00ed58b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the base model\n",
    "from peft import PeftModel\n",
    "\n",
    "base_model_name = \"Qwen/Qwen3-0.6B-Base\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.float32,  # or torch.bfloat16 if CUDA available\n",
    ")\n",
    "\n",
    "# 2. Load LoRA adapters on top of base model\n",
    "model = PeftModel.from_pretrained(model, \"./qwen_lora_patent_real\")\n",
    "\n",
    "# 3. Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./qwen_lora_patent_real\", trust_remote_code=True)\n",
    "\n",
    "# 4. Move to device\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# Test\n",
    "patents = []\n",
    "for prompt in prompts:\n",
    "    prompt += \"\\n\\n Patent Document:\"\n",
    "    patents.append(generate_summary(model, prompt, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "453a1d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vehicular turn signal apparatus is provided for securement to a rear shelf surface proximate a rear window of a vehicular interior in a manner similar to that for securement to a rear window of a vehicle port light unit. The apparatus includes a plurality of modules each containing a pivotally mounted bulb positionable from a first vertical position to a second horizontal position such that when the vehicle enters a traffic cycle the modules are positioned along the length of the rear shelf surface with the bulbs being positioned at predetermined spaced intervals thereafter providing simultaneousaneous illumination upon exit from the traffic cycle.\n",
      "Apparatus for facilitating the machining of workpieces, particularly in the context of grinding a cutting edge of a saw tooth in the direction of both the back and the front face of a tooth in a single grinding process, comprises a grinding tool having a multi-tooth arrangement and gaining access to the cutting edge of a saw tooth in the direction of both the back and the front face of a tooth in a single grinding process. A position detecting mechanism is provided to detect the actual position of the workpiece and grinding means are provided in association with the position detecting mechanism to be adapted to engage and grind the workpiece at the actual position detected by the position detecting mechanism. A coupling arrangement connects the grinding tool with a grinder and comprises a tongue and groove arrangement with a tongue member projecting from the grinding tool and a groove member received in the tongue member at both the back and the front face of a tooth. When the grinder is in place, the coupling arrangement is adapted to be positioned with the workpiece so as to couple the grinder with the grinding tool.\n",
      "In a 3/2 proportional control valve of this invention, an actuating piston which is subjected to the control pressure set in a pilot valve is arranged in the main valve body. A regulating piston is arranged opposite to the actuating piston in a seat which is set into the main valve body by a control piston. The area relationships of the valves are so chosen that at the actuating piston a high pressure gradient obtains and the adjustment dynamics of the regulating piston are increased.\n",
      "Make a patent document based on the following description: A strain gauge for compensating the creep of a support and a process for obtaining such gauges the gauge being of the type wherein a pair of resistors are connected in series and compartmented by a membrane, the resistors being located between the compartment containing the membrane and adjacent to the edge of the gauge. The gauge is bonded to a support and pressure is applied to the membrane to force the resistors to have parallel bars in parallel with each other. The bars are substantially perpendicular to the surface of the support and the strain gauge evolves in line with the applied pressure.\n",
      "An apparatus for cutting a well casing out of shape or broken off from the top provides a simple two piece device consisting of a stationary cutting head (18) and a moving cutting arms (36) having pivotally connected lower ends (38, 42) which may be swung outwardly or inwardly. The cutting arms (36) have cutting blades (58, 60) having a plurality of sets of leading edges (90, 92, 94, 96) provided with a plurality of grooves (88, 98, 100, 102, 104, 106, 108, 110, 112, 114, 116, 118, 120, 122, 124, 126, 128, 130, 132, 134, 136, 138, 140, 142, and 144) connected therewith. The grooves (88, 98, 100, 102, 104, 106, 108, 110, 112, 114, 116, 118, 120, 122, 124, 126, 128, 130, 132, 134, 136, 138, 140, 142, and 144) extend axially along the length of the arms (36) and are circular in shape, having a diameter which is a multiple of the diameter of the cutting blade. The grooves (88, 98, 100, 102, 104, 106, 108, 110, 112, 114, 116, 118, 120, 122, 124, 126, 128, 130, 132, 134, 136, 138, 140, 142, and 144) are of sufficient depth so that a single cutting edge (58, 60) can engage more than one groove (88, 98, 100, 102, 104, 106, 108, 110, 112, 114, 116, 118, 120, 122, 124, 126, 128, 130, 132, 134, 136, 138, 140, 142, and 144) when the arm (36) is swung outwardly. The cutting head (18) is mobile with respect to the stationary portion (16) of the device and is pivotally connected to the stationary portion (16) at a second pivot point (144). When the mobile cutting head (18) is in vertical position, it is opposite to the arm (36) and the grooves (88, 98, 100, 102, 104, 106, 108, 110, 112, 114, 116, 118, 120, 122, 124, 126, 128, 130, 132, 134, 136, 138, 140, 142, and 144) are not connected with the cutting edge (58, 60). To engage more than one groove (88, 98, 100, 102, 104, 106, 108, 110, 112, 114, 116, 118, 120, 122, 124, 126, 128, 130, 132\n",
      "A reliable, pulse-flow supplemental oxygen apparatus for alleviating respiratory ailments is provided which yields substantial savings in oxygen while giving the patient the physiological equivalent of a prescribed continuous stream of oxygen. The apparatus preferably includes a demand oxygen valve operated in a pulse mode by means of electronic control circuitry which, through an appropriate sensor, monitors the patient&#39;s breathing efforts and gives a variable &#34;custom tailored&#34; pulse volume of oxygen to the patient during the very initial stages of each inspiration.\n",
      "A kit for use with 2Ã—4 and 2Ã—6 wood pieces to make sawhorses. The shoulders and toes are constructed for bent metal rods and are secured to brackets or support assemblies that are dimensioned to receive and support the wood piece. A minimal number of nails or screws for securing the wood to the brackets complete the manufacture. In addition, the legs are constructed for bent metal rods and are secured to the brackets in a manner similar to the shoulders and toes. Thus, a lower portion of each leg may be hidden above the shoulders and toes.\n",
      "A shelf tag moulding attachment assembly is provided for securing a product information module to a standard shelf tag moulding in a manner as to inhibit unauthorized removal, while permitting easy removal by authorized personnel through use of a grasping device. The assembly preferably includes a mounting member having projections disposed at one end for effecting biting engagement with one of the tag moulding lips, and a lever arm rotatably coupled to the mounting member having a cam at one end disposed to controllably engage the other lip of the tag moulding. The assembly is demountably secured to the tag moulding when the lever arm is rotated with respect to the mounting member.\n",
      "An analog to digital converter, comprising: an integrator means for producing an output signal and having an input, the integrator means input receiving an analog signal as a first input and a reference signal as a second input, the integrator means output having a threshold which is different for different periods of the second input signal, and an encoder means for encoding the threshold so that the output signal can be interpreted as a digital signal;\n",
      "Method of constructing a macromolecule having a predetermined structure in which base sequences are determined concurrently with the formation of the macromolecule, wherein determining the base sequences comprises comparing a predetermined fragment of the expected base sequence with a present state of the genome and obtaining from a database of expected base sequences additional base sequences therefor, and wherein forming the macromolecule comprises attaching a modified peptide to a predetermined position on a already formed macromolecule having a known structure, wherein modifying the peptide comprises changing a amino acid part of the modified peptide from a part of the amino acid sequence of a ribonucleoside diphosphate carboxykinase to a peptide similar to a fragment of the expected base sequence.\n"
     ]
    }
   ],
   "source": [
    "for patent in patents:\n",
    "    print(patent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dc8e6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m freq = \u001b[32m1000\u001b[39m  \u001b[38;5;66;03m# Hz\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     \u001b[43mwinsound\u001b[49m\u001b[43m.\u001b[49m\u001b[43mBeep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# If you leave this running in the background, turn your speakers on (only works locally)\n",
    "\n",
    "# import platform\n",
    "# import os\n",
    "\n",
    "# if platform.system() == \"Darwin\":\n",
    "#     while True:\n",
    "#         os.system(\"afplay /System/Library/Sounds/Glass.aiff\")\n",
    "# elif platform.system() == \"Windows\":\n",
    "#     import winsound\n",
    "#     duration = 1000  # milliseconds\n",
    "#     freq = 1000  # Hz\n",
    "#     while True:\n",
    "#         winsound.Beep(freq, duration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSC9010",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
